{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issues: \n",
    "* rand_users() sampling duplicate users (should be solved)\n",
    "* returning users less than 120 tweets (solved)\n",
    "* not enough users to make 100 (solved)\n",
    "\n",
    "To do:\n",
    "* batch reading of json files (done)\n",
    "* for users with more than 120 tweets, only consider first 120\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"research\")\n",
    "results_output_filename = os.path.join(data_folder, \"attribution_results_control_2.json\")\n",
    "tweets_folder = os.path.join(data_folder, \"control_tweets\")\n",
    "\n",
    "# [file1, file2, ... ]\n",
    "def read_files_from_dir(datafolder):\n",
    "    \"\"\" returns full file paths from tweets data folder \"\"\"\n",
    "    files_list = [os.path.join(tweets_folder, file) for file in os.listdir(tweets_folder)]\n",
    "    return files_list\n",
    "\n",
    "files_list = read_files_from_dir(tweets_folder)\n",
    "\n",
    "def read_merge_tweets(files):\n",
    "    \"\"\" Given an array of files, read each file (and concatenate?)\"\"\"\n",
    "    dicts = []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as inf:\n",
    "            tweets_dict = json.load(inf)\n",
    "            tweets = remove_low_tweet_authors(tweets_dict)\n",
    "            dicts.append(tweets)\n",
    "    # merge step\n",
    "    super_dict = defaultdict(list)  # uses set to avoid duplicates\n",
    "    for d in dicts:\n",
    "        for k, v in iter(d.items()):\n",
    "            super_dict[k].extend(v)\n",
    "    return super_dict\n",
    "    \n",
    "def copy_keys(table1, keys):\n",
    "    \"\"\" \n",
    "    table1 -- dict that we copy FROM.\n",
    "    table2 -- dict that we copy TO.\n",
    "    \"\"\"\n",
    "    table2 = {}\n",
    "    for key in keys:\n",
    "        if table1[key]:\n",
    "            table2[key] = table1[key]\n",
    "        else: \n",
    "            print(\"key does not exist in table 2\")\n",
    "            break\n",
    "    return table2\n",
    "\n",
    "def rand_users(users, sample_size):\n",
    "    sampled = random.sample(users, sample_size)\n",
    "    return sampled\n",
    "    \n",
    "def remove_hashtag(tweet):\n",
    "    pass\n",
    "\n",
    "def remove_at_symbol(tweet):\n",
    "    pass\n",
    "\n",
    "def remove_low_tweet_authors(tweets):\n",
    "    new_dict = {}\n",
    "    \"\"\" 120 is an optimal number of tweets for authorship attribution (Layton)\"\"\"\n",
    "    for key in tweets:\n",
    "        if len(tweets[key]) < 120:\n",
    "            # tweets.pop(key, None)\n",
    "            continue\n",
    "        else:\n",
    "            new_dict[key] = tweets[key]\n",
    "    return new_dict\n",
    "    \n",
    "# tweets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lpan/Data/research/control_tweets/control_08-10-2015.json\n",
      "/Users/lpan/Data/research/control_tweets/control_2.json\n",
      "/Users/lpan/Data/research/control_tweets/control_3.json\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "# print(tweets_folder)\n",
    "for file in files_list:\n",
    "    print(file)\n",
    "tweets = read_merge_tweets(files_list)\n",
    "print(len(tweets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# authors = {}  ## not needed for actual data mining\n",
    "def join_documents(tweets):\n",
    "    \"\"\" In Python 3, iteritems() has been replaced simply with items() \"\"\"\n",
    "    documents = []\n",
    "    classes = []\n",
    "    author_num = 0\n",
    "    # use sorted() to enforce ordered dict iteration\n",
    "    for key, value in iter(sorted(tweets.items())):\n",
    "        # concatenate documents into one giant corpus\n",
    "        documents.extend(value)\n",
    "        # assign classes values to each respective authors' tweets\n",
    "        classes.extend([author_num] * len(value))\n",
    "        author_num += 1\n",
    "        # print(\"Author: \" + key + \", tweets: \" + str(len(value)))\n",
    "    return documents, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1, Samples: 10, Score: 0.830894671403\n",
      "Run: 2, Samples: 10, Score: 0.614171824479\n",
      "Run: 3, Samples: 10, Score: 0.868862016009\n",
      "Run: 4, Samples: 10, Score: 0.525799264817\n",
      "Run: 5, Samples: 10, Score: 0.576408569936\n",
      "Run: 6, Samples: 10, Score: 0.667343195639\n",
      "Run: 7, Samples: 10, Score: 0.548085994194\n",
      "Run: 8, Samples: 10, Score: 0.580394591249\n",
      "Run: 9, Samples: 10, Score: 0.492624602333\n",
      "Run: 10, Samples: 10, Score: 0.682757697122\n",
      "Run: 11, Samples: 10, Score: 0.714596245509\n",
      "Run: 12, Samples: 10, Score: 0.663632246273\n",
      "Run: 13, Samples: 10, Score: 0.725890160649\n",
      "Run: 14, Samples: 10, Score: 0.657209379559\n",
      "Run: 15, Samples: 10, Score: 0.621050298761\n",
      "Run: 16, Samples: 10, Score: 0.703781287846\n",
      "Run: 17, Samples: 10, Score: 0.827060294868\n",
      "Run: 18, Samples: 10, Score: 0.635579350022\n",
      "Run: 19, Samples: 10, Score: 0.666827002911\n",
      "Run: 20, Samples: 10, Score: 0.506053860011\n",
      "Run: 21, Samples: 10, Score: 0.649073606658\n",
      "Run: 22, Samples: 10, Score: 0.792107856332\n",
      "Run: 23, Samples: 10, Score: 0.812441779983\n",
      "Run: 24, Samples: 10, Score: 0.699765445353\n",
      "Run: 25, Samples: 10, Score: 0.742588363071\n",
      "Run: 26, Samples: 10, Score: 0.606832660798\n",
      "Run: 27, Samples: 10, Score: 0.534568304877\n",
      "Run: 28, Samples: 10, Score: 0.63301774276\n",
      "Run: 29, Samples: 10, Score: 0.637210275773\n",
      "Run: 30, Samples: 10, Score: 0.74435650416\n",
      "Samples: 10, runs: 30\n",
      "Score: 0.665\n",
      "Run: 1, Samples: 20, Score: 0.651203144054\n",
      "Run: 2, Samples: 20, Score: 0.647984803188\n",
      "Run: 3, Samples: 20, Score: 0.387493064928\n",
      "Run: 4, Samples: 20, Score: 0.436221291149\n",
      "Run: 5, Samples: 20, Score: 0.661078412881\n",
      "Run: 6, Samples: 20, Score: 0.664954993785\n",
      "Run: 7, Samples: 20, Score: 0.721372777448\n",
      "Run: 8, Samples: 20, Score: 0.604458729787\n",
      "Run: 9, Samples: 20, Score: 0.618866990564\n",
      "Run: 10, Samples: 20, Score: 0.612987102454\n",
      "Run: 11, Samples: 20, Score: 0.626208695128\n",
      "Run: 12, Samples: 20, Score: 0.708913336995\n",
      "Run: 13, Samples: 20, Score: 0.614814034299\n",
      "Run: 14, Samples: 20, Score: 0.667396888807\n",
      "Run: 15, Samples: 20, Score: 0.53079918141\n",
      "Run: 16, Samples: 20, Score: 0.629529061291\n",
      "Run: 17, Samples: 20, Score: 0.541826899227\n",
      "Run: 18, Samples: 20, Score: 0.615014928319\n",
      "Run: 19, Samples: 20, Score: 0.620525383055\n",
      "Run: 20, Samples: 20, Score: 0.590937991292\n",
      "Run: 21, Samples: 20, Score: 0.492516005256\n",
      "Run: 22, Samples: 20, Score: 0.61089664423\n",
      "Run: 23, Samples: 20, Score: 0.571024245251\n",
      "Run: 24, Samples: 20, Score: 0.589550131895\n",
      "Run: 25, Samples: 20, Score: 0.509415721818\n",
      "Run: 26, Samples: 20, Score: 0.621970039947\n",
      "Run: 27, Samples: 20, Score: 0.544275494858\n",
      "Run: 28, Samples: 20, Score: 0.63350095415\n",
      "Run: 29, Samples: 20, Score: 0.673510751077\n",
      "Run: 30, Samples: 20, Score: 0.663125617597\n",
      "Samples: 20, runs: 30\n",
      "Score: 0.602\n",
      "Run: 1, Samples: 30, Score: 0.552163265046\n",
      "Run: 2, Samples: 30, Score: 0.538866407638\n",
      "Run: 3, Samples: 30, Score: 0.5800686892\n",
      "Run: 4, Samples: 30, Score: 0.500394472407\n",
      "Run: 5, Samples: 30, Score: 0.534397636803\n",
      "Run: 6, Samples: 30, Score: 0.542073749452\n",
      "Run: 7, Samples: 30, Score: 0.500416027539\n",
      "Run: 8, Samples: 30, Score: 0.596386034395\n",
      "Run: 9, Samples: 30, Score: 0.541768544692\n",
      "Run: 10, Samples: 30, Score: 0.440710985651\n",
      "Run: 11, Samples: 30, Score: 0.579928077239\n",
      "Run: 12, Samples: 30, Score: 0.544091591734\n",
      "Run: 13, Samples: 30, Score: 0.648988958546\n",
      "Run: 14, Samples: 30, Score: 0.566679316168\n",
      "Run: 15, Samples: 30, Score: 0.486433424822\n",
      "Run: 16, Samples: 30, Score: 0.620561392583\n",
      "Run: 17, Samples: 30, Score: 0.563986470346\n",
      "Run: 18, Samples: 30, Score: 0.546615592728\n",
      "Run: 19, Samples: 30, Score: 0.643593591866\n",
      "Run: 20, Samples: 30, Score: 0.490629523701\n",
      "Run: 21, Samples: 30, Score: 0.526414203773\n",
      "Run: 22, Samples: 30, Score: 0.512000174096\n",
      "Run: 23, Samples: 30, Score: 0.536117368832\n",
      "Run: 24, Samples: 30, Score: 0.53600349415\n",
      "Run: 25, Samples: 30, Score: 0.521148764653\n",
      "Run: 26, Samples: 30, Score: 0.574943129606\n",
      "Run: 27, Samples: 30, Score: 0.544660967895\n",
      "Run: 28, Samples: 30, Score: 0.566703320929\n",
      "Run: 29, Samples: 30, Score: 0.611845419213\n",
      "Run: 30, Samples: 30, Score: 0.513964285606\n",
      "Samples: 30, runs: 30\n",
      "Score: 0.549\n",
      "Run: 1, Samples: 40, Score: 0.476419217543\n",
      "Run: 2, Samples: 40, Score: 0.582087432062\n",
      "Run: 3, Samples: 40, Score: 0.506208202167\n",
      "Run: 4, Samples: 40, Score: 0.455168537445\n",
      "Run: 5, Samples: 40, Score: 0.50663744364\n",
      "Run: 6, Samples: 40, Score: 0.578667631875\n",
      "Run: 7, Samples: 40, Score: 0.518314554852\n",
      "Run: 8, Samples: 40, Score: 0.501786684321\n",
      "Run: 9, Samples: 40, Score: 0.489036140864\n",
      "Run: 10, Samples: 40, Score: 0.458994828987\n",
      "Run: 11, Samples: 40, Score: 0.504290272157\n",
      "Run: 12, Samples: 40, Score: 0.574389216875\n",
      "Run: 13, Samples: 40, Score: 0.524179771746\n",
      "Run: 14, Samples: 40, Score: 0.56524376363\n",
      "Run: 15, Samples: 40, Score: 0.43262844942\n",
      "Run: 16, Samples: 40, Score: 0.435596412417\n",
      "Run: 17, Samples: 40, Score: 0.515102489788\n",
      "Run: 18, Samples: 40, Score: 0.504892329599\n",
      "Run: 19, Samples: 40, Score: 0.469404718344\n",
      "Run: 20, Samples: 40, Score: 0.528738568494\n",
      "Run: 21, Samples: 40, Score: 0.426652681021\n",
      "Run: 22, Samples: 40, Score: 0.534983818351\n",
      "Run: 23, Samples: 40, Score: 0.549637548458\n",
      "Run: 24, Samples: 40, Score: 0.460152443\n",
      "Run: 25, Samples: 40, Score: 0.468928441386\n",
      "Run: 26, Samples: 40, Score: 0.636933186353\n",
      "Run: 27, Samples: 40, Score: 0.524481856056\n",
      "Run: 28, Samples: 40, Score: 0.547884560448\n",
      "Run: 29, Samples: 40, Score: 0.4754579188\n",
      "Run: 30, Samples: 40, Score: 0.578551315408\n",
      "Samples: 40, runs: 30\n",
      "Score: 0.511\n",
      "Run: 1, Samples: 50, Score: 0.516920973739\n",
      "Run: 2, Samples: 50, Score: 0.523327194007\n",
      "Run: 3, Samples: 50, Score: 0.532656173411\n",
      "Run: 4, Samples: 50, Score: 0.461040289558\n",
      "Run: 5, Samples: 50, Score: 0.538991349784\n",
      "Run: 6, Samples: 50, Score: 0.499092019414\n",
      "Run: 7, Samples: 50, Score: 0.502568486102\n",
      "Run: 8, Samples: 50, Score: 0.509964593696\n",
      "Run: 9, Samples: 50, Score: 0.512119838993\n",
      "Run: 10, Samples: 50, Score: 0.519775771822\n",
      "Run: 11, Samples: 50, Score: 0.498063368947\n",
      "Run: 12, Samples: 50, Score: 0.471706322521\n",
      "Run: 13, Samples: 50, Score: 0.542526513389\n",
      "Run: 14, Samples: 50, Score: 0.503941982675\n",
      "Run: 15, Samples: 50, Score: 0.457783547848\n",
      "Run: 16, Samples: 50, Score: 0.53530759547\n",
      "Run: 17, Samples: 50, Score: 0.435514258828\n",
      "Run: 18, Samples: 50, Score: 0.433872003953\n",
      "Run: 19, Samples: 50, Score: 0.529588838264\n",
      "Run: 20, Samples: 50, Score: 0.565335198254\n",
      "Run: 21, Samples: 50, Score: 0.470594841808\n",
      "Run: 22, Samples: 50, Score: 0.509624624682\n",
      "Run: 23, Samples: 50, Score: 0.456353786428\n",
      "Run: 24, Samples: 50, Score: 0.506167157788\n",
      "Run: 25, Samples: 50, Score: 0.531849562921\n",
      "Run: 26, Samples: 50, Score: 0.546587874469\n",
      "Run: 27, Samples: 50, Score: 0.513097501718\n",
      "Run: 28, Samples: 50, Score: 0.605239519637\n",
      "Run: 29, Samples: 50, Score: 0.523465994406\n",
      "Run: 30, Samples: 50, Score: 0.460071287591\n",
      "Samples: 50, runs: 30\n",
      "Score: 0.507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC # support vector machines\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import grid_search\n",
    "\n",
    "\"\"\" Set up the parameters. 'C' refers to amount of smoothing. \n",
    "Kernel introduces non-linear elements to make them linearly separable(?) \n",
    "\"\"\"\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = SVC()\n",
    "grid = grid_search.GridSearchCV(svr, parameters)\n",
    "\n",
    "# extract character ngrams\n",
    "pipeline = Pipeline([('feature_extraction', \n",
    "                      CountVectorizer(analyzer='char', ngram_range=(3,3))),\n",
    "                     ('classifier', grid)])\n",
    "\n",
    "scores = defaultdict(list)\n",
    "# iter_sample = [10, 20, 30, 40, 50]\n",
    "iter_sample = 10\n",
    "RUNS = 1\n",
    "\n",
    "for sample_size in iter_sample:\n",
    "    count = 0\n",
    "    while count < RUNS:\n",
    "        # print(\"Run: \" + str(count + 1) + \", Samples: \" + str(sample_size))\n",
    "        assert(sample_size <= len(tweets.keys()))\n",
    "        author_subset = rand_users(tweets.keys(), sample_size)\n",
    "        assert(len(author_subset) == sample_size)\n",
    "        tweets_subset = copy_keys(tweets, author_subset)\n",
    "        documents, classes = join_documents(tweets_subset)\n",
    "        score = cross_val_score(pipeline, documents, classes, scoring='f1')\n",
    "        avg_score = np.mean(score)\n",
    "        scores[sample_size].append(avg_score)\n",
    "        print(\"Run: \" + str(count + 1) + \", Samples: \" + str(sample_size) + \", Score: \" + str(avg_score))\n",
    "        count += 1\n",
    "    print(\"Samples: \" + str(sample_size) + \", runs: \" + str(RUNS))\n",
    "    print(\"Score: {:.3f}\".format(np.mean(scores[sample_size])))\n",
    "    # save what we currently have\n",
    "    with open(results_output_filename, 'w') as fp:\n",
    "        json.dump(scores, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c07cea8390f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"whitegrid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "df = pd.DataFrame.from_dict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03d66b94fef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviolin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviolin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "violin = sns.violin('X','Y',df,col='Z',sharex=False,sharey=False)\n",
    "axes = violin.axes\n",
    "axes[0,0].set_ylim(0,)\n",
    "axes[0,1].set_ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
