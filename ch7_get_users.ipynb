{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "consumer_key = \"Your consumer key\"\n",
    "consumer_secret = \"Your consumer secret\"\n",
    "access_token = \"Your access token\"\n",
    "access_token_secret = \"Your access token secret\"\n",
    "\n",
    "# token, token_key, con_secret, con_secret_key\n",
    "authorization = twitter.OAuth(access_token, access_token_secret, consumer_key, consumer_secret)\n",
    "t = twitter.Twitter(auth=authorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "data_folder = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"research\")\n",
    "output_filename = os.path.join(data_folder, \"python_tweets_07-10-2015.json\")\n",
    "tweets_output_filename = os.path.join(data_folder, \"tweets_07-10-2015.json\")\n",
    "\n",
    "# Consider creating a new notebook to gather control group tweets\n",
    "control_group_tweets_filename = os.path.join(data_folder, \"control_tweets_07-10-2015.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_users = []\n",
    "tweets = []\n",
    "user_ids = {}\n",
    "\n",
    "search_results = t.search.tweets(q=\"python-filter:retweets\", lang=\"en\", count=100)['statuses']\n",
    "for tweet in search_results:\n",
    "    if 'text' in tweet:\n",
    "        # record screen name, tweet's text and mapping of tweet to user\n",
    "        original_users.append(tweet['user']['screen_name'])\n",
    "        user_ids[tweet['user']['screen_name']] = tweet['user']['id']\n",
    "        tweets.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_filename = os.path.join(os.path.expanduser(\"~\"), \"Models\", \"research\", \"python_context.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "class NLTKBOW(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \"\"\" \n",
    "    returns a list of dictionaries, where first dict is list of words in first tweet, and so on\n",
    "    \n",
    "    Key: a word\n",
    "    Value: True or false depending if words was discovered\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return [{word: True for word in word_tokenize(document)} for document in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "\"\"\" Load our model from Chapter 6\"\"\"\n",
    "context_classifier = joblib.load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction - are our tweets relevant to the Python programming language?\n",
    "y_pred = context_classifier.predict(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_tweets = [tweets[i] for i in range(len(tweets)) if y_pred[i] == 1]\n",
    "relevant_users = [original_users[i] for i in range(len(tweets)) if y_pred[i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant users: 96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cmyeaton',\n",
       " 'badlogicgames',\n",
       " 'Lesism',\n",
       " 'wcmckeedotcom',\n",
       " 'DavidBurnsworth',\n",
       " 'IamIanHitchings',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'almtorta18',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'dreamintentions',\n",
       " 'BrerTaylor',\n",
       " 'radd_it',\n",
       " 'SamSykesSwears',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'victor254news',\n",
       " 'danielskirk',\n",
       " 'keithwms',\n",
       " 'ka11away',\n",
       " 'shaybaycupcake',\n",
       " 'BeatlesTube',\n",
       " 'programmingncr',\n",
       " 'echosplanet',\n",
       " 'whatta_nerd',\n",
       " 'Python_Agent',\n",
       " 'OfficialUKNews',\n",
       " 'AndrewKoldenTV',\n",
       " 'pypi_updates',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'BeyHiveInFrance',\n",
       " 'kstrauser',\n",
       " 'python_spameggs',\n",
       " 'CutesyOriginals',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " '9_A_6',\n",
       " 'erconger',\n",
       " 'eronim_encabo',\n",
       " 'szescstopni',\n",
       " 'wd_topics_us',\n",
       " 'jordanjphillip1',\n",
       " 'BE8kUGJQ4uhyIVq',\n",
       " 'simbata3',\n",
       " 'simbata3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Relevant users: \" + str(len(relevant_users)))\n",
    "relevant_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant users: 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['9_A_6', 'AndrewKoldenTV', 'BE8kUGJQ4uhyIVq', 'BeatlesTube',\n",
       "       'BeyHiveInFrance', 'BrerTaylor', 'CutesyOriginals',\n",
       "       'DavidBurnsworth', 'IamIanHitchings', 'Lesism', 'OfficialUKNews',\n",
       "       'Python_Agent', 'SamSykesSwears', 'almtorta18', 'badlogicgames',\n",
       "       'cmyeaton', 'danielskirk', 'dreamintentions', 'echosplanet',\n",
       "       'erconger', 'eronim_encabo', 'jordanjphillip1', 'ka11away',\n",
       "       'keithwms', 'kstrauser', 'programmingncr', 'pypi_updates',\n",
       "       'python_spameggs', 'radd_it', 'shaybaycupcake', 'simbata3',\n",
       "       'szescstopni', 'victor254news', 'wcmckeedotcom', 'wd_topics_us',\n",
       "       'whatta_nerd'], \n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: from each unique user, retrieve 120 unique (non-RT?) tweets\n",
    "\n",
    "import numpy as np\n",
    "unique_users = np.unique(relevant_users)\n",
    "print(\"Relevant users: \" + str(len(unique_users)))\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gets 120 of user's most recent tweets\n",
    "import time\n",
    "def get_tweets(user, count):\n",
    "    try:\n",
    "        results = [tweet['text'] for tweet in t.statuses.user_timeline(screen_name=user, count=count) if tweet['text']]\n",
    "    except TypeError as e:\n",
    "        if results is None:\n",
    "            print(\"You probably reached your API limit, waiting for 5 minutes\") \n",
    "            sys.stdout.flush()\n",
    "            time.sleep(5*60)\n",
    "        else:\n",
    "            raise e\n",
    "    except twitter.TwitterHTTPError as e:\n",
    "        pass\n",
    "    finally:\n",
    "        print(\"User: \" + user + \" has been fetched.\\n\")\n",
    "        time.sleep(60) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 9_A_6 has been fetched.\n",
      "\n",
      "User: AndrewKoldenTV has been fetched.\n",
      "\n",
      "User: BE8kUGJQ4uhyIVq has been fetched.\n",
      "\n",
      "User: BeatlesTube has been fetched.\n",
      "\n",
      "User: BeyHiveInFrance has been fetched.\n",
      "\n",
      "User: BrerTaylor has been fetched.\n",
      "\n",
      "User: CutesyOriginals has been fetched.\n",
      "\n",
      "User: DavidBurnsworth has been fetched.\n",
      "\n",
      "User: IamIanHitchings has been fetched.\n",
      "\n",
      "User: Lesism has been fetched.\n",
      "\n",
      "User: OfficialUKNews has been fetched.\n",
      "\n",
      "User: Python_Agent has been fetched.\n",
      "\n",
      "User: SamSykesSwears has been fetched.\n",
      "\n",
      "User: almtorta18 has been fetched.\n",
      "\n",
      "User: badlogicgames has been fetched.\n",
      "\n",
      "User: cmyeaton has been fetched.\n",
      "\n",
      "User: danielskirk has been fetched.\n",
      "\n",
      "User: dreamintentions has been fetched.\n",
      "\n",
      "User: echosplanet has been fetched.\n",
      "\n",
      "User: erconger has been fetched.\n",
      "\n",
      "User: eronim_encabo has been fetched.\n",
      "\n",
      "User: jordanjphillip1 has been fetched.\n",
      "\n",
      "User: ka11away has been fetched.\n",
      "\n",
      "User: keithwms has been fetched.\n",
      "\n",
      "User: kstrauser has been fetched.\n",
      "\n",
      "User: programmingncr has been fetched.\n",
      "\n",
      "User: pypi_updates has been fetched.\n",
      "\n",
      "User: python_spameggs has been fetched.\n",
      "\n",
      "User: radd_it has been fetched.\n",
      "\n",
      "User: shaybaycupcake has been fetched.\n",
      "\n",
      "User: simbata3 has been fetched.\n",
      "\n",
      "User: szescstopni has been fetched.\n",
      "\n",
      "User: victor254news has been fetched.\n",
      "\n",
      "User: wcmckeedotcom has been fetched.\n",
      "\n",
      "User: wd_topics_us has been fetched.\n",
      "\n",
      "User: whatta_nerd has been fetched.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = {}\n",
    "# only consider unique users\n",
    "for screen_name in unique_users: \n",
    "    tweets[screen_name] = get_tweets(screen_name, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save dict to file\n",
    "import json\n",
    "with open(tweets_output_filename, 'w') as fp:\n",
    "    json.dump(tweets, fp)\n",
    "\n",
    "# Consider pruning false positives from twitter disambiguation? (users)\n",
    "len(tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}